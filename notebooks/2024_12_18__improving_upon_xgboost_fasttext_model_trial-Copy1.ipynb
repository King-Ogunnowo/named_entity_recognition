{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "e484fecb-8724-446b-a7e5-d8feef353ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import nltk\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgbm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "9791528b-ced2-4fc5-843e-2abdbd965581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7e86a1bee84c0abd367b3a45a65067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec6fc1cd7a944c09b0d3afd83ddfc36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/179k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c9fae4061b4d35b228645ab83f422e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7969184cf704ccfa2bed6c39bf5f83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59522e9c694f4853affe19dd4483fc93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c630174353e84f7caea4b66630923519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/418 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "917db3cd1b674bf389ac7ff9b4d2aaaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596cff9bd3864fd7b11c5e8a9497d86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a7ab3a6f234acebd513b5941e90c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46490a55d4a642529b950a6356586fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint = \"intfloat/multilingual-e5-base\"\n",
    "\n",
    "embedding_model = SentenceTransformer(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "495d9cd1-4f6c-4c04-9aeb-9092e25aa479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>is_stopword</th>\n",
       "      <th>contains_special_char</th>\n",
       "      <th>contains_numerical_char</th>\n",
       "      <th>POS_contains_spec_char</th>\n",
       "      <th>POS_clean</th>\n",
       "      <th>list_</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>524</td>\n",
       "      <td>Sentence: 23</td>\n",
       "      <td>Iraqi</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-gpe</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Iraqi military officials say tanks and troops ...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>525</td>\n",
       "      <td>Sentence: 23</td>\n",
       "      <td>military</td>\n",
       "      <td>JJ</td>\n",
       "      <td>O</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Iraqi military officials say tanks and troops ...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>526</td>\n",
       "      <td>Sentence: 23</td>\n",
       "      <td>officials</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Iraqi military officials say tanks and troops ...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>527</td>\n",
       "      <td>Sentence: 23</td>\n",
       "      <td>say</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>VBP</td>\n",
       "      <td>Iraqi military officials say tanks and troops ...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>528</td>\n",
       "      <td>Sentence: 23</td>\n",
       "      <td>tanks</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Iraqi military officials say tanks and troops ...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47804</th>\n",
       "      <td>1048393</td>\n",
       "      <td>Sentence: 47950</td>\n",
       "      <td>year</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>NN</td>\n",
       "      <td>The Joint Coordination and Monitoring Board Mo...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47805</th>\n",
       "      <td>1048395</td>\n",
       "      <td>Sentence: 47950</td>\n",
       "      <td>most</td>\n",
       "      <td>JJS</td>\n",
       "      <td>O</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>JJS</td>\n",
       "      <td>The Joint Coordination and Monitoring Board Mo...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47806</th>\n",
       "      <td>1048396</td>\n",
       "      <td>Sentence: 47950</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>IN</td>\n",
       "      <td>The Joint Coordination and Monitoring Board Mo...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47807</th>\n",
       "      <td>1048397</td>\n",
       "      <td>Sentence: 47950</td>\n",
       "      <td>them</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>PRP</td>\n",
       "      <td>The Joint Coordination and Monitoring Board Mo...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47808</th>\n",
       "      <td>1048398</td>\n",
       "      <td>Sentence: 47950</td>\n",
       "      <td>rebels</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "      <td>NNS</td>\n",
       "      <td>The Joint Coordination and Monitoring Board Mo...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47809 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index       Sentence #       Word  POS    Tag is_stopword  \\\n",
       "0          524     Sentence: 23      Iraqi   JJ  B-gpe          No   \n",
       "1          525     Sentence: 23   military   JJ      O          No   \n",
       "2          526     Sentence: 23  officials  NNS      O          No   \n",
       "3          527     Sentence: 23        say  VBP      O          No   \n",
       "4          528     Sentence: 23      tanks  NNS      O          No   \n",
       "...        ...              ...        ...  ...    ...         ...   \n",
       "47804  1048393  Sentence: 47950       year   NN      O          No   \n",
       "47805  1048395  Sentence: 47950       most  JJS      O         Yes   \n",
       "47806  1048396  Sentence: 47950         of   IN      O         Yes   \n",
       "47807  1048397  Sentence: 47950       them  PRP      O         Yes   \n",
       "47808  1048398  Sentence: 47950     rebels  NNS      O          No   \n",
       "\n",
       "      contains_special_char contains_numerical_char  POS_contains_spec_char  \\\n",
       "0                       Yes                      No                   False   \n",
       "1                       Yes                      No                   False   \n",
       "2                       Yes                      No                   False   \n",
       "3                       Yes                      No                   False   \n",
       "4                       Yes                      No                   False   \n",
       "...                     ...                     ...                     ...   \n",
       "47804                   Yes                      No                   False   \n",
       "47805                   Yes                      No                   False   \n",
       "47806                   Yes                      No                   False   \n",
       "47807                   Yes                      No                   False   \n",
       "47808                   Yes                      No                   False   \n",
       "\n",
       "      POS_clean                                              list_  length  \n",
       "0            JJ  Iraqi military officials say tanks and troops ...      25  \n",
       "1            JJ  Iraqi military officials say tanks and troops ...      25  \n",
       "2           NNS  Iraqi military officials say tanks and troops ...      25  \n",
       "3           VBP  Iraqi military officials say tanks and troops ...      25  \n",
       "4           NNS  Iraqi military officials say tanks and troops ...      25  \n",
       "...         ...                                                ...     ...  \n",
       "47804        NN  The Joint Coordination and Monitoring Board Mo...      25  \n",
       "47805       JJS  The Joint Coordination and Monitoring Board Mo...      25  \n",
       "47806        IN  The Joint Coordination and Monitoring Board Mo...      25  \n",
       "47807       PRP  The Joint Coordination and Monitoring Board Mo...      25  \n",
       "47808       NNS  The Joint Coordination and Monitoring Board Mo...      25  \n",
       "\n",
       "[47809 rows x 12 columns]"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/processed_data.csv')\n",
    "sentence_data = pd.read_csv('data/sentence_df.csv').sample(frac = 0.05)\n",
    "combined_data = data.merge(sentence_data, on = 'Sentence #', how = 'inner')\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "f0ac90b9-e8d5-4b28-9902-62c825e85249",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentence_ids, test_sentence_ids = train_test_split(combined_data['Sentence #'].unique(), test_size = 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "6644390e-38ec-4818-9323-7fddd96fd47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = combined_data.loc[combined_data['Sentence #'].isin(train_sentence_ids)]\n",
    "test_set = combined_data.loc[combined_data['Sentence #'].isin(test_sentence_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "c2930e77-6a39-40ed-8fd2-cae6993f1a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('models/token_embedding_dict', 'rb') as file:\n",
    "#     token_embedding_dict = pickle.load(file)\n",
    "\n",
    "\n",
    "# with open('models/sentence_embedding_dict', 'rb') as file:\n",
    "#     sentence_embedding_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "ec073664-b17d-487f-a387-82889664b6ad",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 8220/8220 [02:31<00:00, 54.34it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown = 'ignore')\n",
    "one_hot_encoder.fit(combined_data[['POS_clean']])\n",
    "\n",
    "token_embedding_dict = {token:embedding_model.encode(token) for token in tqdm(combined_data['Word'].unique())}\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('models/token_embedding_dict_e5_base', 'wb') as file:\n",
    "    pickle.dump(token_embedding_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "0e23450c-b7f2-4633-8e6b-013c05fe029d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2398/2398 [01:11<00:00, 33.50it/s]\n"
     ]
    }
   ],
   "source": [
    "sentence_embedding_dict = {sentence:embedding_model.encode(sentence) for sentence in tqdm(combined_data['list_'].unique())}\n",
    "\n",
    "with open('models/sentence_embedding_dict', 'wb') as file:\n",
    "    pickle.dump(sentence_embedding_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b134ad70-f77f-493c-8e03-67a74a7ff5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "bf9b62d0-4284-4ca6-b329-8494b4b17f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_token_embeddings = np.array([token for token in train_set['Word'].map(token_embedding_dict)])\n",
    "train_sentence_embeddings = np.array([sentence for sentence in train_set['list_'].map(sentence_embedding_dict)])\n",
    "train_pos_vector = one_hot_encoder.transform(train_set[['POS_clean']])\n",
    "\n",
    "test_token_embeddings = np.array([token for token in test_set['Word'].map(token_embedding_dict)])\n",
    "test_sentence_embeddings = np.array([sentence for sentence in test_set['list_'].map(sentence_embedding_dict)])\n",
    "test_pos_vector = one_hot_encoder.transform(test_set[['POS_clean']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "5961edfd-caab-4f41-b830-88148acc92b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14133, 768)"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "2e66cfcf-a2ee-43b5-81af-0781daa2b533",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(combined_data['Tag'])\n",
    "\n",
    "y_train = label_encoder.transform(train_set['Tag']).reshape(-1, 1)\n",
    "y_test = label_encoder.transform(test_set['Tag']).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "97a4979b-a268-4d56-88b4-b6ec22bb20e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16],\n",
       "       [ 7],\n",
       "       [16],\n",
       "       ...,\n",
       "       [16],\n",
       "       [ 7],\n",
       "       [15]])"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "509fc2d2-2033-4a72-9f10-48879e6f80cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import *\n",
    "token_input = layers.Input(shape=(768,))  # Token embeddings\n",
    "pos_input = layers.Input(shape=(32,))  # POS one-hot\n",
    "sentence_input = layers.Input(shape=(768,))  # Sentence embedding\n",
    "\n",
    "combined_features = layers.Concatenate()([token_input, pos_input, sentence_input])\n",
    "dot_product = layers.Dot(axes = 1)([token_input, sentence_input])\n",
    "combined_features_with_dot = layers.Concatenate()([combined_features, dot_product])\n",
    "\n",
    "\n",
    "pre_output = layers.Dense(units=128)(combined_features_with_dot)\n",
    "output = layers.Dense(17, activation='softmax')(pre_output)\n",
    "\n",
    "model = Model(inputs = [token_input, pos_input, sentence_input], outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "ea9a3b6b-107f-4560-98a7-34dea61ebed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'], optimizer = 'Adam'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "51bb94d8-3d0f-4bdc-a19c-95a836f6c77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 10:31:51.074605: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [33676,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2024-12-19 10:31:51.074965: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [33676,768]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1053 [============================>.] - ETA: 0s - loss: 0.3530 - accuracy: 0.9036"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 10:31:52.453503: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [14133,768]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1053/1053 [==============================] - 2s 1ms/step - loss: 0.3528 - accuracy: 0.9036 - val_loss: 0.2556 - val_accuracy: 0.9264\n",
      "Epoch 2/10\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 0.2306 - accuracy: 0.9330 - val_loss: 0.2325 - val_accuracy: 0.9341\n",
      "Epoch 3/10\n",
      "1053/1053 [==============================] - 1s 961us/step - loss: 0.2051 - accuracy: 0.9390 - val_loss: 0.2439 - val_accuracy: 0.9292\n",
      "Epoch 4/10\n",
      "1053/1053 [==============================] - 1s 979us/step - loss: 0.1891 - accuracy: 0.9431 - val_loss: 0.2137 - val_accuracy: 0.9368\n",
      "Epoch 5/10\n",
      "1053/1053 [==============================] - 1s 931us/step - loss: 0.1776 - accuracy: 0.9451 - val_loss: 0.2233 - val_accuracy: 0.9358\n",
      "Epoch 6/10\n",
      "1053/1053 [==============================] - 1s 934us/step - loss: 0.1688 - accuracy: 0.9480 - val_loss: 0.2296 - val_accuracy: 0.9358\n",
      "Epoch 7/10\n",
      "1053/1053 [==============================] - 1s 946us/step - loss: 0.1608 - accuracy: 0.9494 - val_loss: 0.2152 - val_accuracy: 0.9367\n",
      "Epoch 8/10\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 0.1529 - accuracy: 0.9513 - val_loss: 0.2256 - val_accuracy: 0.9318\n",
      "Epoch 9/10\n",
      "1053/1053 [==============================] - 1s 944us/step - loss: 0.1468 - accuracy: 0.9536 - val_loss: 0.2222 - val_accuracy: 0.9332\n",
      "Epoch 10/10\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 0.1420 - accuracy: 0.9547 - val_loss: 0.2345 - val_accuracy: 0.9336\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [train_token_embeddings, train_pos_vector, train_sentence_embeddings], y_train,\n",
    "    validation_data = ([test_token_embeddings, test_pos_vector, test_sentence_embeddings], y_test), epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "f9f70225-12b4-4384-baed-1acc174db1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Praise is hugging Nathan such love'"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def fetch_pos_tag(text):\n",
    "    tags = np.array([token.tag_ for token in nlp(text)]).reshape(-1, 1)\n",
    "    return tags\n",
    "    \n",
    "import contractions\n",
    "\n",
    "def clean_text(text):\n",
    "    text = ' '.join([contractions.fix(word) for word in text.split()])\n",
    "    text = re.sub(\"[^a-zA-Z0-9 ]\", \"\", text)\n",
    "    return text    \n",
    "\n",
    "text = \"\"\"Praise is hugging Nathan, such love.\"\"\"\n",
    "\n",
    "cleaned_text = clean_text(text)\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "f2882b50-fa61-45f3-af3d-a56b8454a9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/terra-admin/miniforge3/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_pos_tags = one_hot_encoder.transform(fetch_pos_tag(cleaned_text)).toarray()\n",
    "oof_pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "d9d5f3f0-bd3b-4611-9526-9e64e9f0a184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01119403,  0.0317075 , -0.024415  , ..., -0.06224062,\n",
       "        -0.03176974,  0.04287673],\n",
       "       [-0.00859165,  0.03210774,  0.00502753, ..., -0.02235029,\n",
       "        -0.0382512 ,  0.01503805],\n",
       "       [ 0.02012217,  0.04156946, -0.00516126, ..., -0.05958466,\n",
       "        -0.04319851,  0.04035001],\n",
       "       [ 0.0037807 ,  0.02059454, -0.02499169, ..., -0.0433039 ,\n",
       "        -0.03441045,  0.00815656],\n",
       "       [-0.00976721,  0.01835852, -0.00804532, ..., -0.01832934,\n",
       "        -0.04130954,  0.00316312],\n",
       "       [-0.0018905 ,  0.02066201, -0.00041843, ..., -0.05644192,\n",
       "        -0.01762111,  0.00366273]], dtype=float32)"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embs = np.array([embedding_model.encode(token) for token in cleaned_text.split()])\n",
    "token_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "08fad7ff-f2e0-4848-909d-04c76b0eb02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00320957,  0.01888477, -0.0182494 , ..., -0.10023823,\n",
       "        -0.04328684,  0.03327112],\n",
       "       [ 0.00320957,  0.01888477, -0.0182494 , ..., -0.10023823,\n",
       "        -0.04328684,  0.03327112],\n",
       "       [ 0.00320957,  0.01888477, -0.0182494 , ..., -0.10023823,\n",
       "        -0.04328684,  0.03327112],\n",
       "       [ 0.00320957,  0.01888477, -0.0182494 , ..., -0.10023823,\n",
       "        -0.04328684,  0.03327112],\n",
       "       [ 0.00320957,  0.01888477, -0.0182494 , ..., -0.10023823,\n",
       "        -0.04328684,  0.03327112],\n",
       "       [ 0.00320957,  0.01888477, -0.0182494 , ..., -0.10023823,\n",
       "        -0.04328684,  0.03327112]], dtype=float32)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_embs = embedding_model.encode(cleaned_text)\n",
    "\n",
    "final_sent_embs = np.array([sent_embs for i in range(len(cleaned_text.split()))])\n",
    "\n",
    "final_sent_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "d2bc3dbe-e80d-4086-9240-75e906396d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 24 calls to <function Model.make_predict_function.<locals>.predict_function at 0x337daf1c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 24 calls to <function Model.make_predict_function.<locals>.predict_function at 0x337daf1c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "l = label_encoder.inverse_transform(np.argmax(model.predict([token_embs, oof_pos_tags, final_sent_embs]), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "e4d5a556-d4b4-4aa2-88ef-7967e3f4042b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Praise': 'O',\n",
       " 'is': 'O',\n",
       " 'hugging': 'O',\n",
       " 'Nathan': 'B-per',\n",
       " 'such': 'O',\n",
       " 'love': 'O'}"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{t:l for t, l in zip(cleaned_text.split(), l)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "a2ae263f-c441-43b4-8dc9-d3c4a359877d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>is_stopword</th>\n",
       "      <th>contains_special_char</th>\n",
       "      <th>contains_numerical_char</th>\n",
       "      <th>POS_contains_spec_char</th>\n",
       "      <th>POS_clean</th>\n",
       "      <th>list_</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, Sentence #, Word, POS, Tag, is_stopword, contains_special_char, contains_numerical_char, POS_contains_spec_char, POS_clean, list_, length]\n",
       "Index: []"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.loc[train_set['Word'] == 'Sade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "e9c66e4f-7fbc-4cff-b085-8723957147c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/NER_tensorflow_3_input_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/NER_tensorflow_3_input_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('models/NER_tensorflow_3_input_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "7d608aa2-c7a6-4876-96f9-bea60379b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/one_hot_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(one_hot_encoder, f)\n",
    "\n",
    "with open('models/label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "0781cdb2-bb57-49db-b3ee-472f4f38f184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>is_stopword</th>\n",
       "      <th>contains_special_char</th>\n",
       "      <th>contains_numerical_char</th>\n",
       "      <th>POS_contains_spec_char</th>\n",
       "      <th>POS_clean</th>\n",
       "      <th>list_</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, Sentence #, Word, POS, Tag, is_stopword, contains_special_char, contains_numerical_char, POS_contains_spec_char, POS_clean, list_, length]\n",
       "Index: []"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.loc[combined_data['Word'] == 'open ai']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "7b649c48-011d-4f2f-bcda-ee574a4bafcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B-gpe', 'O', 'B-geo', 'B-org', 'I-org', 'B-tim', 'B-per', 'I-per',\n",
       "       'B-art', 'I-art', 'B-eve', 'B-nat', 'I-nat', 'I-geo', 'I-tim',\n",
       "       'I-eve', 'I-gpe'], dtype=object)"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data['Tag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "73f9de11-1099-44d2-8457-39a6fded9389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #a781f9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Michael R. Bloomberg\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">per</span>\n",
       "</mark>\n",
       " launched a \n",
       "<mark class=\"entity\" style=\"background: #e59edb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    US$85 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">tim</span>\n",
       "</mark>\n",
       " campaign in \n",
       "<mark class=\"entity\" style=\"background: #faa419; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    New York City\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">gpe</span>\n",
       "</mark>\n",
       " to stop pollution by the \n",
       "<mark class=\"entity\" style=\"background: #4ea8de; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    UN Special Envoy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">org</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Span\n",
    "from spacy import displacy\n",
    "\n",
    "# Example text and BIO-tagged tokens\n",
    "tokens = [\"Michael\", \"R.\", \"Bloomberg\", \"launched\", \"a\", \"US$85\", \"million\", \"campaign\",\n",
    "          \"in\", \"New\", \"York\", \"City\", \"to\", \"stop\", \"pollution\", \"by\", \"the\", \"UN\", \"Special\", \"Envoy\"]\n",
    "\n",
    "tags = [\"B-per\", \"I-per\", \"I-per\", \"O\", \"O\", \"B-tim\", \"I-tim\", \"O\",\n",
    "        \"O\", \"B-gpe\", \"I-gpe\", \"I-gpe\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-org\", \"I-org\", \"I-org\"]\n",
    "\n",
    "# Combine tokens into text\n",
    "text = \" \".join(tokens)\n",
    "\n",
    "# Map BIO tags to character-level spans\n",
    "def bio_to_offsets(tokens, tags):\n",
    "    entities = []\n",
    "    start, entity_type = None, None\n",
    "    \n",
    "    for idx, (token, tag) in enumerate(zip(tokens, tags)):\n",
    "        if tag.startswith(\"B-\"):  # Beginning of a new entity\n",
    "            if start is not None:\n",
    "                # Save previous entity\n",
    "                entities.append((start, end, entity_type))\n",
    "            start = len(\" \".join(tokens[:idx])) + (1 if idx > 0 else 0)  # Start char\n",
    "            end = start + len(token)  # End char\n",
    "            entity_type = tag.split(\"-\")[1]  # Extract entity type\n",
    "        elif tag.startswith(\"I-\") and start is not None:  # Inside entity\n",
    "            end = len(\" \".join(tokens[:idx+1]))  # Update end char\n",
    "        else:  # Outside entity\n",
    "            if start is not None:\n",
    "                entities.append((start, end, entity_type))\n",
    "                start, entity_type = None, None\n",
    "\n",
    "    if start is not None:  # Save last entity\n",
    "        entities.append((start, end, entity_type))\n",
    "    return entities\n",
    "\n",
    "# Convert BIO tags to offsets\n",
    "entity_offsets = bio_to_offsets(tokens, tags)\n",
    "\n",
    "# Create spaCy Doc with entities\n",
    "nlp = spacy.blank(\"en\")\n",
    "doc = nlp(text)\n",
    "\n",
    "# Add entities to doc\n",
    "ents = [Span(doc, doc.char_span(start, end).start, doc.char_span(start, end).end, label=label) \n",
    "        for start, end, label in entity_offsets if doc.char_span(start, end)]\n",
    "doc.ents = ents\n",
    "\n",
    "# Define custom colors for entity types\n",
    "colors = {\n",
    "    \"per\": \"#a781f9\",\n",
    "    \"tim\": \"#e59edb\",\n",
    "    \"gpe\": \"#faa419\",\n",
    "    \"geo\": \"#80e5d9\",\n",
    "    \"org\": \"#4ea8de\",\n",
    "    \"art\": \"#d3c8a8\",\n",
    "    \"nat\": \"#81c784\",\n",
    "    \"eve\": \"#ffb74d\"\n",
    "}\n",
    "options = {\"ents\": list(colors.keys()), \"colors\": colors}\n",
    "\n",
    "# Visualize with displacy\n",
    "displacy.render(doc, style=\"ent\", options=options, jupyter=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b205d1-5fdd-41a2-9b88-87e88167cb71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
